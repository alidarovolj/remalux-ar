#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞ TFLite –º–æ–¥–µ–ª–µ–π –Ω–∞ Android —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π TensorFlow Lite benchmark tool —á–µ—Ä–µ–∑ adb
"""

import os
import subprocess
import json
import time
from typing import Dict, List, Optional
from pathlib import Path

class TFLiteBenchmark:
    def __init__(self, device_id: Optional[str] = None):
        self.device_id = device_id
        self.adb_prefix = ['adb'] + (['-s', device_id] if device_id else [])
        self.device_tmp_dir = '/data/local/tmp'
        self.benchmark_binary = 'benchmark_model'
        
    def check_device_connected(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Android —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        try:
            result = subprocess.run(
                self.adb_prefix + ['shell', 'echo', 'test'],
                capture_output=True,
                text=True,
                timeout=5
            )
            return result.returncode == 0
        except subprocess.TimeoutExpired:
            return False
    
    def get_device_info(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ"""
        if not self.check_device_connected():
            raise RuntimeError("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ")
        
        info = {}
        
        # –ú–æ–¥–µ–ª—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        result = subprocess.run(
            self.adb_prefix + ['shell', 'getprop', 'ro.product.model'],
            capture_output=True, text=True
        )
        info['model'] = result.stdout.strip()
        
        # –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä
        result = subprocess.run(
            self.adb_prefix + ['shell', 'getprop', 'ro.product.board'],
            capture_output=True, text=True
        )
        info['board'] = result.stdout.strip()
        
        # –í–µ—Ä—Å–∏—è Android
        result = subprocess.run(
            self.adb_prefix + ['shell', 'getprop', 'ro.build.version.release'],
            capture_output=True, text=True
        )
        info['android_version'] = result.stdout.strip()
        
        # GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ OpenGL)
        result = subprocess.run(
            self.adb_prefix + ['shell', 'dumpsys', 'SurfaceFlinger', '|', 'grep', 'GLES'],
            capture_output=True, text=True, shell=True
        )
        info['gpu_info'] = result.stdout.strip()
        
        return info
    
    def download_benchmark_tool(self) -> bool:
        """–°–∫–∞—á–∞—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π benchmark tool –¥–ª—è TensorFlow Lite"""
        # URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–µ–¥–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–∏–Ω–∞—Ä–Ω–∏–∫–∞
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Å–∫–∞—á–∞—Ç—å —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        print("‚ö†Ô∏è  –î–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å benchmark_model binary")
        print("   –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: https://www.tensorflow.org/lite/performance/measurement")
        print("   –ò–ª–∏ —Å–æ–±–µ—Ä–∏—Ç–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: https://github.com/tensorflow/tensorflow")
        return False
    
    def upload_model(self, model_path: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        
        model_name = os.path.basename(model_path)
        device_model_path = f"{self.device_tmp_dir}/{model_name}"
        
        print(f"üì§ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {model_name} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ...")
        result = subprocess.run(
            self.adb_prefix + ['push', model_path, device_model_path],
            capture_output=True, text=True
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {result.stderr}")
        
        return device_model_path
    
    def run_benchmark(self, device_model_path: str, num_runs: int = 50, 
                     num_threads: int = 4, use_gpu: bool = False) -> Dict:
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–µ–Ω—á–º–∞—Ä–∫ –º–æ–¥–µ–ª–∏"""
        print(f"üîß –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è {os.path.basename(device_model_path)}...")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞
        cmd = [
            'shell',
            f'{self.device_tmp_dir}/{self.benchmark_binary}',
            f'--graph={device_model_path}',
            f'--num_runs={num_runs}',
            f'--num_threads={num_threads}',
            '--enable_op_profiling=true',
            '--verbose'
        ]
        
        if use_gpu:
            cmd.append('--use_gpu=true')
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –±–∏–Ω–∞—Ä–Ω–∏–∫–∞)
        try:
            result = subprocess.run(
                self.adb_prefix + cmd,
                capture_output=True, text=True, timeout=120
            )
            
            if result.returncode != 0:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞: {result.stderr}")
                return self._create_fallback_metrics(device_model_path)
            
            return self._parse_benchmark_output(result.stdout)
            
        except subprocess.TimeoutExpired:
            print("‚è±Ô∏è  –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ —Ç–∞–π–º–∞—É—Ç—É")
            return self._create_fallback_metrics(device_model_path)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return self._create_fallback_metrics(device_model_path)
    
    def _create_fallback_metrics(self, model_path: str) -> Dict:
        """–°–æ–∑–¥–∞—Ç—å –∑–∞–≥–ª—É—à–∫—É –º–µ—Ç—Ä–∏–∫ –∫–æ–≥–¥–∞ –Ω–∞—Ç–∏–≤–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        model_name = os.path.basename(model_path)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏
        try:
            result = subprocess.run(
                self.adb_prefix + ['shell', 'stat', '-c', '%s', model_path],
                capture_output=True, text=True
            )
            model_size_bytes = int(result.stdout.strip()) if result.returncode == 0 else 0
            model_size_mb = model_size_bytes / (1024 * 1024)
        except:
            model_size_mb = 0
        
        return {
            'model_name': model_name,
            'model_size_mb': round(model_size_mb, 1),
            'inference_latency_ms': 'N/A (—Ç—Ä–µ–±—É–µ—Ç—Å—è benchmark binary)',
            'min_latency_ms': 'N/A',
            'max_latency_ms': 'N/A',
            'avg_latency_ms': 'N/A',
            'num_runs': 'N/A',
            'delegate': 'CPU',
            'operator_profiling': 'N/A',
            'note': '–î–ª—è —Ç–æ—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ TensorFlow Lite benchmark tool'
        }
    
    def _parse_benchmark_output(self, output: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ç—å –≤—ã–≤–æ–¥ benchmark tool"""
        lines = output.split('\n')
        metrics = {}
        
        for line in lines:
            line = line.strip()
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if 'Average inference timings in us' in line:
                # –ü–∞—Ä—Å–∏–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è
                pass
            elif 'Min:' in line and 'Max:' in line:
                # –ü–∞—Ä—Å–∏–º –º–∏–Ω/–º–∞–∫—Å –≤—Ä–µ–º—è
                pass
            # –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        return {
            'inference_latency_ms': 'parsed_value',
            'min_latency_ms': 'parsed_min',
            'max_latency_ms': 'parsed_max',
            'operator_profiling': 'parsed_operators'
        }
    
    def benchmark_models(self, model_paths: List[str], output_file: str = 'benchmark_results.json'):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        if not self.check_device_connected():
            raise RuntimeError("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ")
        
        device_info = self.get_device_info()
        print(f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info['model']} (Android {device_info['android_version']})")
        
        results = {
            'timestamp': time.time(),
            'device_info': device_info,
            'models': []
        }
        
        for model_path in model_paths:
            if not os.path.exists(model_path):
                print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
                continue
            
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                device_model_path = self.upload_model(model_path)
                
                # CPU –±–µ–Ω—á–º–∞—Ä–∫
                cpu_metrics = self.run_benchmark(device_model_path, use_gpu=False)
                cpu_metrics['delegate'] = 'CPU'
                
                # GPU –±–µ–Ω—á–º–∞—Ä–∫ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
                gpu_metrics = self.run_benchmark(device_model_path, use_gpu=True)
                gpu_metrics['delegate'] = 'GPU'
                
                results['models'].append({
                    'model_path': model_path,
                    'cpu_metrics': cpu_metrics,
                    'gpu_metrics': gpu_metrics
                })
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è {model_path}: {e}")
                continue
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        return results

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤"""
    import argparse
    
    parser = argparse.ArgumentParser(description='TFLite Model Benchmark Tool')
    parser.add_argument('--models', nargs='+', required=True, 
                       help='–ü—É—Ç–∏ –∫ TFLite –º–æ–¥–µ–ª—è–º –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞')
    parser.add_argument('--device', help='ID Android —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    parser.add_argument('--output', default='benchmark_results.json',
                       help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫–µ—Ä
    benchmark = TFLiteBenchmark(device_id=args.device)
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫–∏
        results = benchmark.benchmark_models(args.models, args.output)
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print("\nüìä –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞:")
        for model_result in results['models']:
            model_name = os.path.basename(model_result['model_path'])
            cpu_latency = model_result['cpu_metrics'].get('avg_latency_ms', 'N/A')
            gpu_latency = model_result['gpu_metrics'].get('avg_latency_ms', 'N/A')
            print(f"  {model_name}: CPU={cpu_latency}ms, GPU={gpu_latency}ms")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main()) 